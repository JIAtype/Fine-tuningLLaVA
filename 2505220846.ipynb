{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71f40a9",
   "metadata": {},
   "source": [
    " LLaVA-v1.5 多模态大模型在不同配置下的性能对比\n",
    "\n",
    "# 参数解释\n",
    "| 参数名 | 含义说明 |\n",
    "| -------------- | ---------------------------------------------------------------------------------------- |\n",
    "| Version | 模型版本，这里都是 LLaVA-1.5 |\n",
    "| Size | 模型规模，7B 表示 70亿参数，13B 表示 130亿参数 |\n",
    "| Schedule | 微调方式/训练策略。full_ft-1e 表示全参数微调，lora-1e 表示 LoRA 微调（低秩适应） |\n",
    "| Checkpoint | 模型权重的存储位置（如 HuggingFace 上的仓库名） |\n",
    "| VQAv2 | 在 VQAv2 数据集上的准确率（视觉问答） |\n",
    "| GQA | 在 GQA 数据集上的准确率（图像问答） |\n",
    "| VizWiz | 在 VizWiz 数据集上的准确率（视觉辅助问答） |\n",
    "| SQA | 在 SQA 数据集上的准确率（表格问答） |\n",
    "| TextVQA | 在 TextVQA 数据集上的准确率（文本视觉问答） |\n",
    "| POPE | 在 POPE 数据集上的准确率（视觉推理） |\n",
    "| MME | MME 测试集得分（多模态评测） |\n",
    "| MM-Bench | MM-Bench 测试集得分（多模态基准测试） |\n",
    "| MM-Bench-CN | MM-Bench 中文测试集得分 |\n",
    "| SEED | SEED 测试集得分（多模态理解） |\n",
    "| LLaVA-Bench-Wild| LLaVA-Bench-Wild 测试集得分（野外多模态测试） |\n",
    "| MM-Vet | MM-Vet 测试集得分（多模态推理） |\n",
    "\n",
    "# 总结建议\n",
    "如果你追求最高性能，建议选择 13B + full_ft-1e 版本。\n",
    "如果你资源有限或需要快速微调，可以选择 7B + lora-1e 版本。\n",
    "LoRA 微调适合个人和小团队，训练和部署成本低。\n",
    "全参数微调适合有较强算力的团队，效果更优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://huggingface.co/liuhaotian/llava-v1.5-13b-lora\n",
    "这个版本性能最好\n",
    "\n",
    "https://huggingface.co/liuhaotian/llava-v1.5-7b-lora\n",
    "这个版本先做一个尝试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f170f86a",
   "metadata": {},
   "source": [
    "# llava-v1.5-13b-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"image-text-to-text\", model=\"liuhaotian/llava-v1.5-13b-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58462633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"liuhaotian/llava-v1.5-13b-lora\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"liuhaotian/llava-v1.5-13b-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4a7d2",
   "metadata": {},
   "source": [
    "# liuhaotian/llava-v1.5-7b-lora\n",
    "\n",
    "https://huggingface.co/liuhaotian/llava-v1.5-7b-lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285d0a6",
   "metadata": {},
   "source": [
    "# 跟着[教程](https://www.youtube.com/watch?v=rbof1eYekvA)的尝试\n",
    "[代码](https://colab.research.google.com/drive/10NLrfBKgt9ntPoQYQ24rEVWU-2rr1xf1)\n",
    "D:\\aiml\\llm_cv\\Copy_of_fine_tune_VLM_LlaVa.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65feec7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'llava (Python 3.10.16)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_path = \"./checkpoints/vicuna-7b-v1-5\"  \n",
    "\n",
    "# quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    # quantization_config=quantization_config,\n",
    "    # device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae00ae8",
   "metadata": {},
   "source": [
    "[多模态大模型 LLaVA 微调教程](https://www.cnblogs.com/xiangcaoacao/p/18188100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c17e32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu118\n",
      "True\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa655706",
   "metadata": {},
   "source": [
    "依赖冲突,版本不匹配会导致 LLaVA 运行时出错或不兼容，比如模型加载失败、API 不兼容等。\n",
    "所以安装LLaVA 1.2.2.post1 推荐用的torch==2.1.2和torchvision==0.16.2。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
