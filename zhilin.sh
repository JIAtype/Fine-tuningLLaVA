python llava/train/train_mem.py --model_name_or_path liuhaotian/llava-v1.5-7b --version v1 --data_path data/my_dataset/annotations/train.json --image_folder data/my_dataset/images --vision_tower openai/clip-vit-large-patch14-336 --mm_projector_type mlp2x_gelu --image_aspect_ratio pad --tune_mm_mlp_adapter True --fp16 True --output_dir ./checkpoints/llava-mydata-v1.5-7b --num_train_epochs 3 --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --gradient_accumulation_steps 2 --evaluation_strategy "no" --save_strategy "epoch" --learning_rate 2e-5 --save_total_limit 2 --logging_steps 10 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 0